{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def read_data(PATH):\n",
    "    all_data = []\n",
    "    for path, dirs, files in os.walk(PATH):\n",
    "        dirs.sort()\n",
    "        temp = []\n",
    "        for filename in files:\n",
    "            filePath = path + '/' + filename\n",
    "            f = open( filePath, 'r' ).read()\n",
    "            temp.append(parse_article(f))\n",
    "\n",
    "        if temp:\n",
    "            all_data.append(temp)\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "def parse_article(article):\n",
    "#     TODO: tokenize sentence and transform to lower and padding\n",
    "    word_tokens = []\n",
    "    article = article.lower()\n",
    "    sentences = article.split('\\n')\n",
    "    for s in sentences:\n",
    "        tokens = word_tokenize(s)\n",
    "        tokens.insert(0, '<s>')\n",
    "        tokens.append('<\\s>')\n",
    "        word_tokens.append(tokens)\n",
    "    word_tokens.pop()\n",
    "    return word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kn_model(train_data):\n",
    "#     TODO: Bigram() + Pcontination()\n",
    "    l_bigram = []\n",
    "    l_unigram = []\n",
    "    for a in train_data:\n",
    "        for s in a:\n",
    "            for i in range(len(s)-1):\n",
    "                l_bigram.append(s[i]+','+s[i+1])\n",
    "                l_unigram.append(s[i])\n",
    "            l_unigram.append(s[-1])\n",
    "            \n",
    "    d_bigram = Counter(l_bigram)\n",
    "    d_unigram = Counter(l_unigram)\n",
    "    num_words = len(l_unigram)\n",
    "    \n",
    "    return d_bigram, d_unigram, num_words\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def predict(d_bigram, d_unigram, num_words, sentence, discount):\n",
    "    scores = []\n",
    "    len_models = len(d_bigram)\n",
    "    \n",
    "    \n",
    "    for i in range(len_models):\n",
    "        score = 0\n",
    "        for j in range(len(sentence)-1):\n",
    "            bi_str = sentence[j] + ',' + sentence[j+1]\n",
    "            c1 = max(d_bigram[i][bi_str] - discount, 0)\n",
    "            c2 = max(d_unigram[i][sentence[j]], 1)\n",
    "\n",
    "            w1_bitypes = [value for key , value in d_bigram[i].items() if sentence[j]+',' in key]\n",
    "            num_w1types = max(len(w1_bitypes), 1)\n",
    "            num_w1bi = max(sum(w1_bitypes), 1)\n",
    "            lam = (discount / num_w1bi) * num_w1types\n",
    "\n",
    "            w2_bitypes = sum([1 for key , value in d_bigram[i].items() if ','+sentence[j+1] in key])\n",
    "            len_bi = len(d_bigram[i])\n",
    "            p_con = max((w2_bitypes - discount) / len_bi, 0)\n",
    "            v = c1 / c2 + lam * p_con\n",
    "            score += math.log(max(v, 1e-8))\n",
    "        scores.append(score)\n",
    "        \n",
    "    return np.argmax(scores)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def score_article(lst):\n",
    "#     TODO: get label that has highest scores\n",
    "    return max(set(lst), key=lst.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load and preprocess training data\n",
      "start training\n",
      "start testing\n",
      "0 Hits:90\n",
      "1 Hits:4\n",
      "2 Hits:78\n",
      "3 Hits:83\n",
      "4 Hits:25\n",
      "5 Hits:14\n",
      "6 Hits:49\n",
      "7 Hits:3\n",
      "8 Hits:15\n",
      "9 Hits:6\n",
      "10 Hits:43\n",
      "11 Hits:7\n",
      "Accuracy:  0.6105417276720352\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "NUM_MODELS = 12\n",
    "DISCOUNT = 0.75\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    print(\"load and preprocess training data\")\n",
    "    train_PATH = './reuters/r_train/'\n",
    "    all_training_data = read_data(train_PATH)\n",
    "    \n",
    "    print('start training')\n",
    "#     TODO: build kn model\n",
    "    d_bigram = []\n",
    "    d_unigram = []\n",
    "    num_words = []\n",
    "    for i in range(NUM_MODELS):\n",
    "        b, u, n = kn_model(all_training_data[i])\n",
    "        d_bigram.append(b)\n",
    "        d_unigram.append(u)\n",
    "        num_words.append(n)\n",
    "        \n",
    "        \n",
    "    print(\"start testing\")\n",
    "    test_PATH = './reuters/r_test'\n",
    "    all_testing_data = read_data(test_PATH)\n",
    "    \n",
    "    total_hit = 0\n",
    "    test_data_len = sum(len(t) for t in all_testing_data)\n",
    "        \n",
    "    for idx, label in enumerate(all_testing_data):\n",
    "        label_hit = 0\n",
    "        for article in label:\n",
    "            p_labels = []\n",
    "            for sentence in article:\n",
    "                s_label = predict(d_bigram, d_unigram, num_words, sentence, DISCOUNT)\n",
    "                p_labels.append(s_label)\n",
    "#                 print(s_label)\n",
    "            p = score_article(p_labels)\n",
    "            if  idx == p:\n",
    "                total_hit += 1\n",
    "                label_hit += 1\n",
    "              \n",
    "        print('{0} Hits:{1}'.format(idx, label_hit))\n",
    "\n",
    "    print('Accuracy: ', total_hit/test_data_len)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
